import streamlit as st
import pandas as pd
import re
import math
import time
import zipfile
from io import BytesIO
from pathlib import Path
from openpyxl import load_workbook


# =========================
# Settings
# =========================
DETAIL_LIMIT = 9                # detail_1 ~ detail_9
DEFAULT_ID_COL = "A"            # AíŒŒì¼ ìƒí’ˆì•„ì´ë”” ê¸°ë³¸ ì—´
DEFAULT_CHUNK = 100             # 100í–‰ ë‹¨ìœ„ ë¶„í• 
DEFAULT_OUT_SHEET_INDEX = 0     # b.xlsx í…œí”Œë¦¿ì—ì„œ ê°’ì„ ì“¸ ì‹œíŠ¸ (0=ì²« ì‹œíŠ¸)

# =========================
# Utils
# =========================
def col_idx(col: str) -> int:
    """Excel column letters -> 0-based index (supports AA, AB, AC...)"""
    idx = 0
    for c in col.upper():
        idx = idx * 26 + (ord(c) - ord("A") + 1)
    return idx - 1


def extract_bracket_items(val):
    """
    - [ ... ] ë¸”ë¡ì´ ì—¬ëŸ¬ ê°œë©´ ê°ê° ì•„ì´í…œìœ¼ë¡œ ì¶”ì¶œ
    - ë¸”ë¡ ë‚´ë¶€ì— ì½¤ë§ˆê°€ ìˆìœ¼ë©´ ì¶”ê°€ ë¶„ë¦¬
    - ëŒ€ê´„í˜¸ê°€ ì—†ìœ¼ë©´ ì½¤ë§ˆ ë¶„ë¦¬ë¡œ í´ë°±
    """
    if pd.isna(val):
        return []
    s = str(val).strip()
    if not s:
        return []

    blocks = re.findall(r"\[([^\]]+)\]", s)
    items = []

    if blocks:
        for blk in blocks:
            blk = blk.strip()
            if not blk:
                continue
            if "," in blk:
                items.extend([p.strip() for p in blk.split(",") if p.strip()])
            else:
                items.append(blk)
    else:
        s2 = s.replace("[", "").replace("]", "").strip()
        if not s2:
            return []
        items = [p.strip() for p in s2.split(",") if p.strip()]

    return items


def uniq_keep_order(seq):
    return list(dict.fromkeys(seq))


def build_bd_from_group(a: pd.DataFrame, pid_series: pd.Series, pid_value: str, one_line: bool):
    """
    BD ê·œì¹™:
    - main: Sì—ì„œ ì²« ìœ íš¨ main 1ê°œ
    - detail: Tì—ì„œ ì „ì²´ë¥¼ ëª¨ì•„ ì¤‘ë³µ ì œê±° í›„ detail_1~detail_9
    - one_line=Trueë©´ ì¤„ë°”ê¿ˆ ì—†ì´ í•œ ì¤„ë¡œ í•©ì¹¨(ì˜µì…˜ ìƒí’ˆì—ì„œ ì‚¬ìš©)
    """
    mask = (pid_series == pid_value).to_numpy()

    s_all = a.iloc[:, col_idx("S")]
    t_all = a.iloc[:, col_idx("T")]

    main_candidates = []
    for sv in s_all[mask]:
        main_candidates.extend(extract_bracket_items(sv))
    main = main_candidates[0] if main_candidates else ""

    detail_items = []
    for tv in t_all[mask]:
        detail_items.extend(extract_bracket_items(tv))

    detail_items = uniq_keep_order([x for x in detail_items if x])[:DETAIL_LIMIT]

    parts = []
    if main:
        parts.append(f"main^|^https://m.lastorder.in/{main}")
    for i, it in enumerate(detail_items, start=1):
        parts.append(f"detail_{i}^|^https://m.lastorder.in/{it}")

    return " ".join(parts) if one_line else "\n".join(parts)


def join_unique(vals):
    cleaned = [str(v).strip() for v in vals if pd.notna(v) and str(v).strip()]
    return "^|^".join(uniq_keep_order(cleaned))


def validate_a_df(a: pd.DataFrame, id_col_letter: str):
    """
    í˜„ì¬ ë¡œì§ì—ì„œ ì°¸ì¡°í•˜ëŠ” AíŒŒì¼ ì»¬ëŸ¼(ì—‘ì…€ ìœ„ì¹˜ ê¸°ì¤€)
    C, D, E, H, I, J, M, P, S, T, + ìƒí’ˆì•„ì´ë””(id_col_letter)
    """
    required = ["C", "D", "E", "H", "I", "J", "M", "P", "S", "T", id_col_letter]
    max_needed = max(col_idx(c) for c in required)
    if a.shape[1] <= max_needed:
        missing = [c for c in required if col_idx(c) >= a.shape[1]]
        return False, f"AíŒŒì¼ ì»¬ëŸ¼ ë¶€ì¡±: {missing} (í˜„ì¬ ì»¬ëŸ¼ ìˆ˜: {a.shape[1]})"
    return True, ""


def make_b_rows_from_a(a: pd.DataFrame, id_col_letter: str):
    """
    A -> B (í–‰ ë¦¬ìŠ¤íŠ¸/í–‰ ë°ì´í„°)
    - ìƒí’ˆì•„ì´ë”” ì¤‘ë³µì´ë©´ ì˜µì…˜ê·¸ë£¹
    - ê°™ì€ ìƒí’ˆì•„ì´ë””ëŠ” 1í–‰ìœ¼ë¡œ ë¬¶ìŒ
    - ì˜µì…˜ê·¸ë£¹:
        AH='y', AI='ì„ íƒ'
        AJ = ì˜µì…˜ê°’(E) ^|^ ì—°ê²° (ì¤‘ë³µ ì œê±°, ë“±ì¥ ìˆœ)
        AN = ì˜µì…˜ì¬ê³ (M) : AJ ì˜µì…˜ê°’ ìˆœì„œì— ë§ì¶° ë§¤ì¹­í•œ ë’¤ ^|^ ì—°ê²°
        O/Q/AW(íŒë§¤ì¢…ë£Œì¼) = ê·¸ë£¹ ìµœì†Œ ë‚ ì§œ
        BD = ê·¸ë£¹ ì „ì²´ ì´ë¯¸ì§€ í•©ì¹˜ê¸° + (ì˜µì…˜ì¼ ê²½ìš°) í•œ ì¤„(one_line)
    - ë¹„ì˜µì…˜:
        O/Q/AWëŠ” ê·¸ë£¹ ìµœì†Œ(ê²°ê³¼ì ìœ¼ë¡œ ë‹¨ì¼ì´ë¼ ë™ì¼)
        BDëŠ” ì¤„ë°”ê¿ˆ ìœ ì§€
    - ë§¤ì¹­ ë’¤í‹€ë¦¼ ë°©ì§€: ëŒ€í‘œí–‰/SeriesëŠ” reset_index(drop=True) + to_numpy ì‚¬ìš©
    """
    pid = a.iloc[:, col_idx(id_col_letter)].astype(str).fillna("").str.strip()
    dup_mask = pid.duplicated(keep=False)

    # ëŒ€í‘œí–‰(ê° pid ì²« í–‰) - ì¸ë±ìŠ¤ ë¦¬ì…‹ì´ ë§¤ìš° ì¤‘ìš”(align ë°©ì§€)
    rep_mask = ~pid.duplicated(keep="first")
    a_rep = a.loc[rep_mask].reset_index(drop=True)
    pid_rep = pid.loc[rep_mask].reset_index(drop=True)

    option_pids = set(pid[dup_mask])

    # íŒë§¤ì¢…ë£Œì¼ ê·¸ë£¹ ìµœì†Œ
    p_all_dt = pd.to_datetime(a.iloc[:, col_idx("P")], errors="coerce")
    p_min_map = p_all_dt.groupby(pid).min()

    # ì˜µì…˜ê°’(E)
    e_series = a.iloc[:, col_idx("E")]

    # ì˜µì…˜ê°’(AJ) ë§µ (ì¤‘ë³µ ì œê±°, ìˆœì„œ ìœ ì§€)
    opt_value_map = e_series.groupby(pid, sort=False).apply(join_unique).to_dict()

    # ì˜µì…˜ì¬ê³ (AN): AíŒŒì¼ Mì—´ ê¸°ë°˜, ì˜µì…˜ê°’ ìˆœì„œì— ë§ì¶° ë§¤ì¹­
    m_stock_series = a.iloc[:, col_idx("M")]
    opt_stock_map = {}
    df_opt = pd.DataFrame({"pid": pid, "opt": e_series, "stk": m_stock_series})

    for pid_val, grp in df_opt.groupby("pid", sort=False):
        # ì˜µì…˜ê°’ ë“±ì¥ ìˆœì„œ + ì¤‘ë³µ ì œê±°
        opt_vals_raw = [str(v).strip() for v in grp["opt"].tolist() if pd.notna(v) and str(v).strip()]
        opt_vals = uniq_keep_order(opt_vals_raw)

        stocks_out = []
        for ov in opt_vals:
            sub = grp.loc[grp["opt"].astype(str).str.strip() == ov, "stk"]

            chosen = ""
            for sv in sub.tolist():
                if pd.isna(sv):
                    continue
                ss = str(sv).strip()
                if ss != "" and ss.lower() != "nan":
                    chosen = ss
                    break
            stocks_out.append(chosen)

        opt_stock_map[pid_val] = "^|^".join(stocks_out)

    # ê²°ê³¼ í–‰ ìƒì„± (B í…œí”Œë¦¿ì— ì“¸ â€œì—´ë¬¸ì:ê°’â€ dict ë¦¬ìŠ¤íŠ¸)
    out_rows = []
    for i in range(len(a_rep)):
        pid_i = pid_rep.iloc[i]
        is_option = pid_i in option_pids

        row = {}

        # ê³ ì •
        row["A"] = 1
        row["B"] = 2
        row["C"] = 217089
        row["D"] = 1011307
        row["K"] = "n"

        # ê¸°ë³¸ ë§¤í•‘(ëŒ€í‘œí–‰ ê¸°ì¤€)
        row["H"]  = a_rep.iloc[:, col_idx("D")].to_numpy()[i]  # ìƒí’ˆëª…
        row["U"]  = a_rep.iloc[:, col_idx("I")].to_numpy()[i]
        row["V"]  = a_rep.iloc[:, col_idx("H")].to_numpy()[i]
        row["AC"] = a_rep.iloc[:, col_idx("M")].to_numpy()[i]  # ê¸°ì¡´ ìš”êµ¬: AC <- M (ëŒ€í‘œí–‰)
        row["AY"] = a_rep.iloc[:, col_idx("C")].to_numpy()[i]
        row["AZ"] = a_rep.iloc[:, col_idx("C")].to_numpy()[i]

        # W = (H - J) ê³„ì‚° í›„ "-1"
        h_val = pd.to_numeric(a_rep.iloc[:, col_idx("H")], errors="coerce").fillna(0).to_numpy()[i]
        j_val = pd.to_numeric(a_rep.iloc[:, col_idx("J")], errors="coerce").fillna(0).to_numpy()[i]
        row["W"] = f"{int(h_val - j_val)}-1"

        # íŒë§¤ì¢…ë£Œì¼: ê·¸ë£¹ ìµœì†Œ
        pmin = p_min_map.get(pid_i, pd.NaT)
        if pd.isna(pmin):
            row["O"] = 1
            row["Q"] = "2999-12-31"
            row["AW"] = "2999-12-31"
        else:
            d = pd.Timestamp(pmin).strftime("%Y-%m-%d")
            row["O"] = 2
            row["Q"] = d
            row["AW"] = d

        # ì˜µì…˜ ê´€ë ¨
        if is_option:
            row["AH"] = "y"
            row["AI"] = "ì„ íƒ"
            row["AJ"] = opt_value_map.get(pid_i, "")
            row["AN"] = opt_stock_map.get(pid_i, "")  # âœ… ì˜µì…˜ì¬ê³  (AíŒŒì¼ Mì—´)
            # ì˜µì…˜ì´ë¯¸ì§€: í•œ ì¤„ë¡œ í•©ì¹¨
            row["BD"] = build_bd_from_group(a, pid, pid_i, one_line=True)
        else:
            # ë¹„ì˜µì…˜: BD ì¤„ë°”ê¿ˆ ìœ ì§€
            row["BD"] = build_bd_from_group(a, pid, pid_i, one_line=False)

        out_rows.append(row)

    return out_rows


def apply_rows_to_template(template_bytes: bytes, rows: list[dict], sheet_index: int, start_row: int = 2):
    """
    b.xlsx í…œí”Œë¦¿(ì „ì²´ íƒ­ ìœ ì§€)ì— rowsë¥¼ ì²« ì‹œíŠ¸(ê¸°ë³¸) start_rowë¶€í„° ê°’ìœ¼ë¡œ ê¸°ì…
    - ê¸°ì¡´ í…œí”Œë¦¿ êµ¬ì¡°/ë‹¤ë¥¸ ì‹œíŠ¸ ìœ ì§€
    """
    wb = load_workbook(BytesIO(template_bytes))
    ws = wb.worksheets[sheet_index]

    for i, row in enumerate(rows):
        excel_row = start_row + i
        for col_letter, val in row.items():
            ws[f"{col_letter}{excel_row}"] = val

    out = BytesIO()
    wb.save(out)
    out.seek(0)
    return out.getvalue()


def split_rows(rows: list[dict], chunk_size: int):
    if chunk_size <= 0:
        return [rows]
    return [rows[i:i+chunk_size] for i in range(0, len(rows), chunk_size)] or [[]]


# =========================
# Streamlit UI
# =========================
st.set_page_config(page_title="Aâ†’B ë³€í™˜ê¸°(ì˜µì…˜/í…œí”Œë¦¿ ìœ ì§€/ë¶„í• )", layout="wide")
st.title("ğŸ“¦ AíŒŒì¼ â†’ Bí…œí”Œë¦¿(b.xlsx) ìë™ ë³€í™˜ê¸° (ì˜µì…˜/ì´ë¯¸ì§€/ì¬ê³ /ë¶„í• /ë¦¬í¬íŠ¸)")

with st.expander("ì—…ë¡œë“œ íŒ", expanded=True):
    st.write(
        "- í´ë”ì²˜ëŸ¼ ì“°ë ¤ë©´ **í´ë” ì•ˆ xlsx ì—¬ëŸ¬ ê°œë¥¼ í•œ ë²ˆì— ë“œë˜ê·¸&ë“œë¡­** í•˜ì„¸ìš”.\n"
        "- `b.xlsx` í…œí”Œë¦¿ì€ ì•±ì—ì„œ ì—…ë¡œë“œí•˜ê±°ë‚˜, ì„œë²„/ë¡œì»¬ ì‹¤í–‰ ì‹œ ê°™ì€ í´ë”ì— ë‘¬ë„ ë©ë‹ˆë‹¤.\n"
        "- ê²°ê³¼ëŠ” **b.xlsx í…œí”Œë¦¿ì˜ ëª¨ë“  íƒ­ì„ ìœ ì§€**í•œ ìƒíƒœë¡œ, ì²« ì‹œíŠ¸ì— ê°’ë§Œ ì±„ì›ë‹ˆë‹¤.\n"
        "- ì˜µì…˜ ê·¸ë£¹ì€ ìƒí’ˆì•„ì´ë”” ì¤‘ë³µìœ¼ë¡œ íŒë‹¨í•˜ë©°, ì˜µì…˜ ì´ë¯¸ì§€(BD)ëŠ” í•œ ì¤„ë¡œ í•©ì¹©ë‹ˆë‹¤."
    )

# Sidebar controls
st.sidebar.header("ì„¤ì •")
id_col_letter = st.sidebar.text_input("AíŒŒì¼ ìƒí’ˆì•„ì´ë”” ì»¬ëŸ¼(ì—‘ì…€ ë¬¸ì)", value=DEFAULT_ID_COL).strip().upper()
chunk_size = st.sidebar.number_input("ë¶„í•  ì €ì¥(í–‰)", min_value=10, max_value=5000, value=DEFAULT_CHUNK, step=10)
sheet_index = st.sidebar.number_input("í…œí”Œë¦¿ì— ì“¸ ì‹œíŠ¸ ì¸ë±ìŠ¤(0=ì²« ì‹œíŠ¸)", min_value=0, max_value=30, value=DEFAULT_OUT_SHEET_INDEX, step=1)

# Template uploader (optional)
template_file = st.file_uploader("B í…œí”Œë¦¿(b.xlsx) ì—…ë¡œë“œ (ì„ íƒ: ì—…ë¡œë“œ ì•ˆ í•˜ë©´ ê¸°ë³¸ b.xlsx ì‚¬ìš©)", type=["xlsx"])

# A files uploader
a_files = st.file_uploader("AíŒŒì¼ ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type=["xlsx"], accept_multiple_files=True)

run_btn = st.button("ğŸš€ ë³€í™˜ ì‹œì‘", disabled=not a_files)

def get_template_bytes():
    # If user uploaded template, use it. Otherwise try to read local ./b.xlsx
    if template_file is not None:
        return template_file.getvalue()
    # fallback: local file (works when running locally/server with b.xlsx in same folder)
    local_path = Path("b.xlsx")
    if local_path.exists():
        return local_path.read_bytes()
    raise FileNotFoundError("b.xlsx í…œí”Œë¦¿ì´ ì—†ìŠµë‹ˆë‹¤. b.xlsxë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ ì•± í´ë”ì— ë‘ì„¸ìš”.")

if run_btn:
    t0 = time.time()
    st.info("ì²˜ë¦¬ ì¤‘...")

    try:
        template_bytes = get_template_bytes()
    except Exception as e:
        st.error(f"í…œí”Œë¦¿ ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.stop()

    summary_rows = []
    error_rows = []

    zip_buf = BytesIO()
    with zipfile.ZipFile(zip_buf, "w", zipfile.ZIP_DEFLATED) as zf:
        for uf in a_files:
            if uf.name.startswith("~$"):
                continue

            started = time.time()
            status = "OK"
            msg = ""
            input_rows = 0
            out_files = 0

            try:
                a_df = pd.read_excel(uf)
                input_rows = len(a_df)

                ok, vmsg = validate_a_df(a_df, id_col_letter)
                if not ok:
                    raise ValueError(vmsg)

                rows = make_b_rows_from_a(a_df, id_col_letter)

                # split by chunk_size
                chunks = split_rows(rows, int(chunk_size))
                for idx, chunk in enumerate(chunks, start=1):
                    out_xlsx = apply_rows_to_template(
                        template_bytes=template_bytes,
                        rows=chunk,
                        sheet_index=int(sheet_index),
                        start_row=2
                    )
                    out_name = f"{Path(uf.name).stem}_part{idx:03d}.xlsx"
                    zf.writestr(out_name, out_xlsx)
                    out_files += 1

            except Exception as e:
                status = "FAIL"
                msg = str(e)
                error_rows.append({"file": uf.name, "reason": msg})

            elapsed = round(time.time() - started, 3)
            summary_rows.append({
                "file": uf.name,
                "status": status,
                "input_rows": input_rows,
                "output_files": out_files,
                "seconds": elapsed,
                "message": msg
            })

        # summary_report.csv
        summary_df = pd.DataFrame(summary_rows)
        zf.writestr("summary_report.csv", summary_df.to_csv(index=False).encode("utf-8-sig"))

        # errors.csv
        if error_rows:
            errors_df = pd.DataFrame(error_rows)
            zf.writestr("errors.csv", errors_df.to_csv(index=False).encode("utf-8-sig"))

    zip_buf.seek(0)
    total_sec = round(time.time() - t0, 2)

    st.success(f"âœ… ì™„ë£Œ! ì´ ì†Œìš” {total_sec}s")
    st.subheader("ğŸ“Š ìš”ì•½ ë¦¬í¬íŠ¸")
    st.dataframe(pd.DataFrame(summary_rows), use_container_width=True)

    if error_rows:
        st.subheader("âš ï¸ ì—ëŸ¬")
        st.dataframe(pd.DataFrame(error_rows), use_container_width=True)

    st.download_button(
        "ğŸ“¦ ê²°ê³¼ ZIP ë‹¤ìš´ë¡œë“œ (ì—‘ì…€ + ë¦¬í¬íŠ¸ í¬í•¨)",
        data=zip_buf,
        file_name="B_result.zip",
        mime="application/zip"
    )
